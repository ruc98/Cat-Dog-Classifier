{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Conv2D,MaxPooling2D,Dense,Dropout,Flatten\n",
    "from keras import optimizers\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from classification_models import ResNet18\n",
    "import sys\n",
    "import os\n",
    "from time import time\n",
    "from keras.models import load_model\n",
    "from keras.models import Sequential\n",
    "\"\"\"\n",
    "Adapted from keras example cifar10_cnn.py\n",
    "Train ResNet-18 on the CIFAR10 small images dataset.\n",
    "\n",
    "GPU run command with Theano backend (with TensorFlow, the GPU is automatically used):\n",
    "    THEANO_FLAGS=mode=FAST_RUN,device=gpu,floatX=float32 python cifar10.py\n",
    "\"\"\"\n",
    "from __future__ import print_function\n",
    "from keras.datasets import cifar10\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.utils import np_utils\n",
    "from keras.callbacks import ReduceLROnPlateau, CSVLogger, EarlyStopping, TensorBoard, LearningRateScheduler\n",
    "from keras import backend as K\n",
    "import numpy as np\n",
    "from keras.layers import AveragePooling2D\n",
    "from keras.layers import (\n",
    "    Input,\n",
    "    Activation,\n",
    "    Dense,\n",
    "    Flatten,\n",
    "    Dropout\n",
    ")\n",
    "from keras.layers import Dense\n",
    "from keras.models import Model\n",
    "from keras import optimizers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "TRAIN_DIR='/home/rahulchakwate/My_tensorflow/DataSets/cats_and_dogs_2/train'\n",
    "IMG_SIZE=224\n",
    "LR=1e-3\n",
    "MODEL_NAME='cat-dog-convnet'\n",
    "\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'\n",
    "\n",
    "def create_label(image_name):\n",
    "    word_label=image_name.split('.')[-3]\n",
    "    if word_label=='cat':\n",
    "        return np.array([1,0])\n",
    "    elif word_label=='dog':\n",
    "        return np.array([0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data=[]\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        path=os.path.join(TRAIN_DIR,img)\n",
    "        img_data=cv2.imread(path,cv2.IMREAD_COLOR)\n",
    "        img_data=cv2.resize(img_data,(IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img_data),create_label(img)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy',training_data)\n",
    "    return training_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 5489/25000 [01:30<05:20, 60.90it/s]"
     ]
    }
   ],
   "source": [
    "train_data=create_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train=train_data\n",
    "X_train=np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\n",
    "y_train=np.array([i[1] for i in train])\n",
    "X_train=\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def lr_schedule(epoch):\n",
    "    \"\"\"Learning Rate Schedule\n",
    "\n",
    "    Learning rate is scheduled to be reduced after 20,40 epochs.\n",
    "    Called automatically every epoch as part of callbacks during training.\n",
    "\n",
    "    # Arguments\n",
    "        epoch (int): The number of epochs\n",
    "\n",
    "    # Returns\n",
    "        lr (float32): learning rate\n",
    "    \"\"\"\n",
    "    lr = 1e-5\n",
    "    if epoch > 20:\n",
    "        lr = lr*0.1\n",
    "    return lr\n",
    "\n",
    "#lr_scheduler = LearningRateScheduler(lr_schedule, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base_model = ResNet18(input_shape=(50,50,3), weights='imagenet', include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pool2 = AveragePooling2D(pool_size=(4,4),\n",
    "                                 strides=(1, 1))(base_model.output)\n",
    "base_model1=Model(inputs=base_model.input, outputs=pool2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "data (InputLayer)               (None, 50, 50, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bn_data (BatchNormalization)    (None, 50, 50, 3)    9           data[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_19 (ZeroPadding2 (None, 56, 56, 3)    0           bn_data[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv0 (Conv2D)                  (None, 25, 25, 64)   9408        zero_padding2d_19[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "bn0 (BatchNormalization)        (None, 25, 25, 64)   256         conv0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "relu0 (Activation)              (None, 25, 25, 64)   0           bn0[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_20 (ZeroPadding2 (None, 27, 27, 64)   0           relu0[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "pooling0 (MaxPooling2D)         (None, 13, 13, 64)   0           zero_padding2d_20[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn1 (BatchNormaliz (None, 13, 13, 64)   256         pooling0[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu1 (Activation) (None, 13, 13, 64)   0           stage1_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_21 (ZeroPadding2 (None, 15, 15, 64)   0           stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv1 (Conv2D)     (None, 13, 13, 64)   36864       zero_padding2d_21[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_bn2 (BatchNormaliz (None, 13, 13, 64)   256         stage1_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_relu2 (Activation) (None, 13, 13, 64)   0           stage1_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_22 (ZeroPadding2 (None, 15, 15, 64)   0           stage1_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_conv2 (Conv2D)     (None, 13, 13, 64)   36864       zero_padding2d_22[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit1_sc (Conv2D)        (None, 13, 13, 64)   4096        stage1_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_9 (Add)                     (None, 13, 13, 64)   0           stage1_unit1_conv2[0][0]         \n",
      "                                                                 stage1_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn1 (BatchNormaliz (None, 13, 13, 64)   256         add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu1 (Activation) (None, 13, 13, 64)   0           stage1_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_23 (ZeroPadding2 (None, 15, 15, 64)   0           stage1_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv1 (Conv2D)     (None, 13, 13, 64)   36864       zero_padding2d_23[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_bn2 (BatchNormaliz (None, 13, 13, 64)   256         stage1_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_relu2 (Activation) (None, 13, 13, 64)   0           stage1_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_24 (ZeroPadding2 (None, 15, 15, 64)   0           stage1_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage1_unit2_conv2 (Conv2D)     (None, 13, 13, 64)   36864       zero_padding2d_24[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_10 (Add)                    (None, 13, 13, 64)   0           stage1_unit2_conv2[0][0]         \n",
      "                                                                 add_9[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn1 (BatchNormaliz (None, 13, 13, 64)   256         add_10[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu1 (Activation) (None, 13, 13, 64)   0           stage2_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_25 (ZeroPadding2 (None, 15, 15, 64)   0           stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv1 (Conv2D)     (None, 7, 7, 128)    73728       zero_padding2d_25[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_bn2 (BatchNormaliz (None, 7, 7, 128)    512         stage2_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_relu2 (Activation) (None, 7, 7, 128)    0           stage2_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_26 (ZeroPadding2 (None, 9, 9, 128)    0           stage2_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_conv2 (Conv2D)     (None, 7, 7, 128)    147456      zero_padding2d_26[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit1_sc (Conv2D)        (None, 7, 7, 128)    8192        stage2_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_11 (Add)                    (None, 7, 7, 128)    0           stage2_unit1_conv2[0][0]         \n",
      "                                                                 stage2_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn1 (BatchNormaliz (None, 7, 7, 128)    512         add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu1 (Activation) (None, 7, 7, 128)    0           stage2_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_27 (ZeroPadding2 (None, 9, 9, 128)    0           stage2_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv1 (Conv2D)     (None, 7, 7, 128)    147456      zero_padding2d_27[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_bn2 (BatchNormaliz (None, 7, 7, 128)    512         stage2_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_relu2 (Activation) (None, 7, 7, 128)    0           stage2_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_28 (ZeroPadding2 (None, 9, 9, 128)    0           stage2_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage2_unit2_conv2 (Conv2D)     (None, 7, 7, 128)    147456      zero_padding2d_28[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_12 (Add)                    (None, 7, 7, 128)    0           stage2_unit2_conv2[0][0]         \n",
      "                                                                 add_11[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn1 (BatchNormaliz (None, 7, 7, 128)    512         add_12[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu1 (Activation) (None, 7, 7, 128)    0           stage3_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_29 (ZeroPadding2 (None, 9, 9, 128)    0           stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv1 (Conv2D)     (None, 4, 4, 256)    294912      zero_padding2d_29[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_bn2 (BatchNormaliz (None, 4, 4, 256)    1024        stage3_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_relu2 (Activation) (None, 4, 4, 256)    0           stage3_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_30 (ZeroPadding2 (None, 6, 6, 256)    0           stage3_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_conv2 (Conv2D)     (None, 4, 4, 256)    589824      zero_padding2d_30[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit1_sc (Conv2D)        (None, 4, 4, 256)    32768       stage3_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_13 (Add)                    (None, 4, 4, 256)    0           stage3_unit1_conv2[0][0]         \n",
      "                                                                 stage3_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn1 (BatchNormaliz (None, 4, 4, 256)    1024        add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu1 (Activation) (None, 4, 4, 256)    0           stage3_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_31 (ZeroPadding2 (None, 6, 6, 256)    0           stage3_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv1 (Conv2D)     (None, 4, 4, 256)    589824      zero_padding2d_31[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_bn2 (BatchNormaliz (None, 4, 4, 256)    1024        stage3_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_relu2 (Activation) (None, 4, 4, 256)    0           stage3_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_32 (ZeroPadding2 (None, 6, 6, 256)    0           stage3_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage3_unit2_conv2 (Conv2D)     (None, 4, 4, 256)    589824      zero_padding2d_32[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_14 (Add)                    (None, 4, 4, 256)    0           stage3_unit2_conv2[0][0]         \n",
      "                                                                 add_13[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn1 (BatchNormaliz (None, 4, 4, 256)    1024        add_14[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu1 (Activation) (None, 4, 4, 256)    0           stage4_unit1_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_33 (ZeroPadding2 (None, 6, 6, 256)    0           stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv1 (Conv2D)     (None, 4, 4, 512)    1179648     zero_padding2d_33[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit1_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit1_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_34 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit1_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_34[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit1_sc (Conv2D)        (None, 4, 4, 512)    131072      stage4_unit1_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "add_15 (Add)                    (None, 4, 4, 512)    0           stage4_unit1_conv2[0][0]         \n",
      "                                                                 stage4_unit1_sc[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn1 (BatchNormaliz (None, 4, 4, 512)    2048        add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu1 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn1[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_35 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv1 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_35[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_bn2 (BatchNormaliz (None, 4, 4, 512)    2048        stage4_unit2_conv1[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_relu2 (Activation) (None, 4, 4, 512)    0           stage4_unit2_bn2[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "zero_padding2d_36 (ZeroPadding2 (None, 6, 6, 512)    0           stage4_unit2_relu2[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "stage4_unit2_conv2 (Conv2D)     (None, 4, 4, 512)    2359296     zero_padding2d_36[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "add_16 (Add)                    (None, 4, 4, 512)    0           stage4_unit2_conv2[0][0]         \n",
      "                                                                 add_15[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "bn1 (BatchNormalization)        (None, 4, 4, 512)    2048        add_16[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "relu1 (Activation)              (None, 4, 4, 512)    0           bn1[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_2 (AveragePoo (None, 1, 1, 512)    0           relu1[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 11,186,889\n",
      "Trainable params: 11,178,947\n",
      "Non-trainable params: 7,942\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model1.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22000/22000 [==============================] - 298s 14ms/step\n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_train=base_model1.predict(X_train[:22000], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 40s 13ms/step\n"
     ]
    }
   ],
   "source": [
    "bottleneck_features_val=base_model1.predict(X_train[22000:], verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(22000, 1, 1, 512)\n",
      "(3000, 1, 1, 512)\n"
     ]
    }
   ],
   "source": [
    "print(bottleneck_features_train.shape)\n",
    "print(bottleneck_features_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nb_classes=2\n",
    "train_data=bottleneck_features_train\n",
    "validation_data=bottleneck_features_val\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(nb_classes, activation='softmax',kernel_initializer='random_normal'))\n",
    "\n",
    "tensorboard = TensorBoard(log_dir=\"log2/{}\".format(time()))\n",
    "\n",
    "adam=optimizers.Adam(lr=1e-5)\n",
    "model.compile(optimizer=adam,\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/rahulchakwate/.local/lib/python3.5/site-packages/ipykernel_launcher.py:5: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 22000 samples, validate on 3000 samples\n",
      "Epoch 1/200\n",
      "\n",
      "Epoch 00001: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 4s 167us/step - loss: 0.8008 - acc: 0.5790 - val_loss: 0.5863 - val_acc: 0.6947\n",
      "Epoch 2/200\n",
      "\n",
      "Epoch 00002: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 132us/step - loss: 0.6493 - acc: 0.6593 - val_loss: 0.5353 - val_acc: 0.7360\n",
      "Epoch 3/200\n",
      "\n",
      "Epoch 00003: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 2s 107us/step - loss: 0.5921 - acc: 0.6996 - val_loss: 0.5121 - val_acc: 0.7587\n",
      "Epoch 4/200\n",
      "\n",
      "Epoch 00004: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 2s 105us/step - loss: 0.5624 - acc: 0.7150 - val_loss: 0.4983 - val_acc: 0.7693\n",
      "Epoch 5/200\n",
      "\n",
      "Epoch 00005: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 2s 105us/step - loss: 0.5412 - acc: 0.7305 - val_loss: 0.4893 - val_acc: 0.7727\n",
      "Epoch 6/200\n",
      "\n",
      "Epoch 00006: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 2s 105us/step - loss: 0.5265 - acc: 0.7429 - val_loss: 0.4828 - val_acc: 0.7750\n",
      "Epoch 7/200\n",
      "\n",
      "Epoch 00007: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 2s 105us/step - loss: 0.5110 - acc: 0.7504 - val_loss: 0.4760 - val_acc: 0.7800\n",
      "Epoch 8/200\n",
      "\n",
      "Epoch 00008: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 2s 105us/step - loss: 0.5018 - acc: 0.7567 - val_loss: 0.4712 - val_acc: 0.7827\n",
      "Epoch 9/200\n",
      "\n",
      "Epoch 00009: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 139us/step - loss: 0.4968 - acc: 0.7630 - val_loss: 0.4678 - val_acc: 0.7797\n",
      "Epoch 10/200\n",
      "\n",
      "Epoch 00010: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 127us/step - loss: 0.4888 - acc: 0.7660 - val_loss: 0.4645 - val_acc: 0.7833\n",
      "Epoch 11/200\n",
      "\n",
      "Epoch 00011: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 119us/step - loss: 0.4801 - acc: 0.7707 - val_loss: 0.4608 - val_acc: 0.7873\n",
      "Epoch 12/200\n",
      "\n",
      "Epoch 00012: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 130us/step - loss: 0.4821 - acc: 0.7710 - val_loss: 0.4588 - val_acc: 0.7863\n",
      "Epoch 13/200\n",
      "\n",
      "Epoch 00013: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 128us/step - loss: 0.4730 - acc: 0.7764 - val_loss: 0.4579 - val_acc: 0.7810\n",
      "Epoch 14/200\n",
      "\n",
      "Epoch 00014: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 118us/step - loss: 0.4697 - acc: 0.7780 - val_loss: 0.4547 - val_acc: 0.7880\n",
      "Epoch 15/200\n",
      "\n",
      "Epoch 00015: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 145us/step - loss: 0.4677 - acc: 0.7799 - val_loss: 0.4531 - val_acc: 0.7880\n",
      "Epoch 16/200\n",
      "\n",
      "Epoch 00016: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 154us/step - loss: 0.4618 - acc: 0.7820 - val_loss: 0.4515 - val_acc: 0.7877\n",
      "Epoch 17/200\n",
      "\n",
      "Epoch 00017: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 145us/step - loss: 0.4621 - acc: 0.7839 - val_loss: 0.4500 - val_acc: 0.7883\n",
      "Epoch 18/200\n",
      "\n",
      "Epoch 00018: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 4s 180us/step - loss: 0.4573 - acc: 0.7845 - val_loss: 0.4495 - val_acc: 0.7863\n",
      "Epoch 19/200\n",
      "\n",
      "Epoch 00019: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 144us/step - loss: 0.4549 - acc: 0.7880 - val_loss: 0.4471 - val_acc: 0.7893\n",
      "Epoch 20/200\n",
      "\n",
      "Epoch 00020: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 148us/step - loss: 0.4515 - acc: 0.7871 - val_loss: 0.4464 - val_acc: 0.7897\n",
      "Epoch 21/200\n",
      "\n",
      "Epoch 00021: LearningRateScheduler setting learning rate to 1e-05.\n",
      "22000/22000 [==============================] - 3s 129us/step - loss: 0.4497 - acc: 0.7888 - val_loss: 0.4455 - val_acc: 0.7917\n",
      "Epoch 22/200\n",
      "\n",
      "Epoch 00022: LearningRateScheduler setting learning rate to 2.267573696145125e-08.\n",
      "22000/22000 [==============================] - 3s 134us/step - loss: 0.4456 - acc: 0.7925 - val_loss: 0.4455 - val_acc: 0.7913\n",
      "Epoch 23/200\n",
      "\n",
      "Epoch 00023: LearningRateScheduler setting learning rate to 2.066115702479339e-08.\n",
      "22000/22000 [==============================] - 3s 128us/step - loss: 0.4462 - acc: 0.7914 - val_loss: 0.4455 - val_acc: 0.7913\n",
      "Epoch 24/200\n",
      "\n",
      "Epoch 00024: LearningRateScheduler setting learning rate to 1.890359168241966e-08.\n",
      "22000/22000 [==============================] - 3s 145us/step - loss: 0.4497 - acc: 0.7914 - val_loss: 0.4455 - val_acc: 0.7913\n",
      "Epoch 25/200\n",
      "\n",
      "Epoch 00025: LearningRateScheduler setting learning rate to 1.7361111111111113e-08.\n",
      "22000/22000 [==============================] - 3s 155us/step - loss: 0.4472 - acc: 0.7927 - val_loss: 0.4455 - val_acc: 0.7913\n",
      "Epoch 26/200\n",
      "\n",
      "Epoch 00026: LearningRateScheduler setting learning rate to 1.6e-08.\n",
      "22000/22000 [==============================] - 3s 137us/step - loss: 0.4480 - acc: 0.7900 - val_loss: 0.4455 - val_acc: 0.7913\n",
      "Epoch 27/200\n",
      "\n",
      "Epoch 00027: LearningRateScheduler setting learning rate to 1.4792899408284025e-08.\n",
      "22000/22000 [==============================] - 3s 130us/step - loss: 0.4502 - acc: 0.7875 - val_loss: 0.4455 - val_acc: 0.7917\n",
      "Epoch 28/200\n",
      "\n",
      "Epoch 00028: LearningRateScheduler setting learning rate to 1.3717421124828534e-08.\n",
      "22000/22000 [==============================] - 2s 109us/step - loss: 0.4498 - acc: 0.7896 - val_loss: 0.4455 - val_acc: 0.7917\n",
      "Epoch 29/200\n",
      "\n",
      "Epoch 00029: LearningRateScheduler setting learning rate to 1.2755102040816328e-08.\n",
      "22000/22000 [==============================] - 3s 123us/step - loss: 0.4467 - acc: 0.7920 - val_loss: 0.4454 - val_acc: 0.7917\n",
      "Epoch 30/200\n",
      "\n",
      "Epoch 00030: LearningRateScheduler setting learning rate to 1.1890606420927468e-08.\n",
      "22000/22000 [==============================] - 3s 127us/step - loss: 0.4477 - acc: 0.7910 - val_loss: 0.4454 - val_acc: 0.7917\n",
      "Epoch 31/200\n",
      "\n",
      "Epoch 00031: LearningRateScheduler setting learning rate to 1.1111111111111112e-08.\n",
      "22000/22000 [==============================] - 4s 166us/step - loss: 0.4456 - acc: 0.7911 - val_loss: 0.4454 - val_acc: 0.7917\n",
      "Epoch 32/200\n",
      "\n",
      "Epoch 00032: LearningRateScheduler setting learning rate to 1.040582726326743e-08.\n",
      "22000/22000 [==============================] - 3s 143us/step - loss: 0.4464 - acc: 0.7918 - val_loss: 0.4454 - val_acc: 0.7913\n",
      "Epoch 33/200\n",
      "\n",
      "Epoch 00033: LearningRateScheduler setting learning rate to 9.765625e-09.\n",
      "22000/22000 [==============================] - 3s 145us/step - loss: 0.4477 - acc: 0.7895 - val_loss: 0.4454 - val_acc: 0.7913\n",
      "Epoch 34/200\n",
      "\n",
      "Epoch 00034: LearningRateScheduler setting learning rate to 9.18273645546373e-09.\n",
      "22000/22000 [==============================] - 3s 152us/step - loss: 0.4478 - acc: 0.7925 - val_loss: 0.4454 - val_acc: 0.7913\n",
      "Epoch 35/200\n",
      "\n",
      "Epoch 00035: LearningRateScheduler setting learning rate to 8.650519031141869e-09.\n",
      "22000/22000 [==============================] - 3s 139us/step - loss: 0.4485 - acc: 0.7914 - val_loss: 0.4454 - val_acc: 0.7913\n",
      "Epoch 36/200\n",
      "\n",
      "Epoch 00036: LearningRateScheduler setting learning rate to 8.16326530612245e-09.\n",
      "22000/22000 [==============================] - 3s 133us/step - loss: 0.4437 - acc: 0.7917 - val_loss: 0.4454 - val_acc: 0.7913\n",
      "Epoch 37/200\n",
      "\n",
      "Epoch 00037: LearningRateScheduler setting learning rate to 7.71604938271605e-09.\n",
      " 1600/22000 [=>............................] - ETA: 2s - loss: 0.4539 - acc: 0.7794"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-14a882ef8bde>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m22000\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m               \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m               callbacks=[tensorboard, lr_scheduler])\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2670\u001b[0m                     \u001b[0;34m'In order to feed symbolic tensors to a Keras model '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2671\u001b[0m                     'in TensorFlow, you need tensorflow 1.8 or higher.')\n\u001b[0;32m-> 2672\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2673\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_legacy_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2652\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2653\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2654\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2655\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    903\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    904\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 905\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    906\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    907\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1138\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1139\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1140\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1141\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1142\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1321\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1310\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1311\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1312\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1313\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1314\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.5/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1418\u001b[0m         return tf_session.TF_Run(\n\u001b[1;32m   1419\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1420\u001b[0;31m             status, run_metadata)\n\u001b[0m\u001b[1;32m   1421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1422\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(train_data, y_train[:22000],\n",
    "              nb_epoch=200,\n",
    "              validation_data=(validation_data, y_train[22000:]),\n",
    "              shuffle=True,\n",
    "              callbacks=[tensorboard, lr_scheduler])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "     os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model2=load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history2=model2.fit(x=X_train,y=y_train,batch_size=4,epochs=10,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "if not os.path.isdir(save_dir):\n",
    "     os.makedirs(save_dir)\n",
    "model_path = os.path.join(save_dir, model_name)\n",
    "model2.save(model_path)\n",
    "print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model3=load_model(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adam=optimizers.Adam(lr=0.00001)\n",
    "model3.compile(optimizer=adam,loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "history3=model3.fit(x=X_train,y=y_train,batch_size=4,epochs=5,verbose=1,validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(history.history.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(history.history['acc'])\n",
    "plt.plot(history.history['val_acc'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'val'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "keras.callbacks.TensorBoard(log_dir='/tmp/log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
