{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function\n",
    "\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from random import shuffle\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tensorflow.python.client import device_lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#hyperparams\n",
    "LR=1e-3\n",
    "batch_size=32\n",
    "epochs=4\n",
    "\n",
    "\n",
    "#Variables\n",
    "TRAIN_DIR='/home/rahulchakwate/My_tensorflow/DataSets/cats_and_dogs_2/train'\n",
    "IMG_SIZE=50\n",
    "nb_classes=2\n",
    "\n",
    "\n",
    "#Placeholders\n",
    "images_ph=tf.placeholder(tf.float32, shape=[None,IMG_SIZE,IMG_SIZE,1])\n",
    "labels_ph=tf.placeholder(tf.float32, shape=[None,nb_classes])\n",
    "\n",
    "#save model path\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name='checkpoints\\\\'\n",
    "if not os.path.isdir(save_dir):\n",
    "     os.makedirs(save_dir)\n",
    "model_save_name = os.path.join(save_dir, model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "def create_label(image_name):\n",
    "    word_label=image_name.split('.')[-3]\n",
    "    if word_label=='cat':\n",
    "        return np.array([1,0])\n",
    "    elif word_label=='dog':\n",
    "        return np.array([0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_train_data():\n",
    "    training_data=[]\n",
    "    for img in tqdm(os.listdir(TRAIN_DIR)):\n",
    "        path=os.path.join(TRAIN_DIR,img)\n",
    "        img_data=cv2.imread(path,cv2.IMREAD_GRAYSCALE)\n",
    "        img_data=cv2.resize(img_data,(IMG_SIZE,IMG_SIZE))\n",
    "        training_data.append([np.array(img_data),create_label(img)])\n",
    "    shuffle(training_data)\n",
    "    np.save('train_data.npy',training_data)\n",
    "    return training_data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#train_data=create_train_data()\n",
    "train_data=np.load('/home/rahulchakwate/My_tensorflow/train_data.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 50, 50, 1)\n",
      "(1000, 50, 50, 1)\n",
      "(2000, 2)\n",
      "(1000, 2)\n",
      "2000\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "train=train_data\n",
    "X_train=np.array([i[0] for i in train]).reshape(-1,IMG_SIZE,IMG_SIZE,1)\n",
    "y_train=np.array([i[1] for i in train])\n",
    "\n",
    "images=X_train[0:2000]\n",
    "val_images=X_train[2000:3000]\n",
    "labels=y_train[0:2000]\n",
    "val_labels=y_train[2000:3000]\n",
    "\n",
    "total_batch=images.shape[0]\n",
    "val_batch_size=val_images.shape[0]\n",
    "print(images.shape)\n",
    "print(val_images.shape)\n",
    "print(labels.shape)\n",
    "print(val_labels.shape)\n",
    "print(total_batch)\n",
    "print(val_batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch_dispatch(batch_size, batch ,images ,labels):\n",
    "    batch_images=images[batch_size*(batch):batch_size*(batch+1)]\n",
    "    batch_labels=labels[batch_size*(batch):batch_size*(batch+1)]\n",
    "    return batch_images, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def cnn_model(images_ph,nb_classes):\n",
    "    #input_layer=tf.reshape(features[\"x\"],[-1,28,28,1])\n",
    "    conv1=tf.layers.conv2d(images_ph, 32,[5,5],padding=\"same\",activation=tf.nn.relu)\n",
    "    pool1=tf.layers.max_pooling2d(conv1,[2,2],strides=2)\n",
    "    conv2=tf.layers.conv2d(pool1,64,[3,3],padding=\"same\",activation=tf.nn.relu)\n",
    "    pool2=tf.layers.max_pooling2d(conv2,[2,2],strides=2)\n",
    "    flat1=tf.layers.flatten(pool2)\n",
    "    dense1=tf.layers.dense(flat1,1024,activation=tf.nn.relu)\n",
    "    drop1=tf.layers.dropout(dense1,0.5)\n",
    "    logits=tf.layers.dense(drop1,nb_classes,activation=None)\n",
    "    print(logits.shape)\n",
    "    return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainacc(logits, labels):\n",
    "  \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "  Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size], with values in the\n",
    "      range [0, NUM_CLASSES).\n",
    "  Returns:\n",
    "    A scalar int32 tensor with the number of examples (out of batch_size)\n",
    "    that were predicted correctly.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope('train_accuracy') as scope:\n",
    "      correct = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "      correct = tf.cast(correct, tf.float32)\n",
    "      accuracy = tf.reduce_mean(correct)\n",
    "      print(correct.shape)\n",
    "      tf.summary.scalar(scope.name+'/train_accuracy', accuracy)\n",
    "      return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def valacc(logits, labels):\n",
    "  \"\"\"Evaluate the quality of the logits at predicting the label.\n",
    "  Args:\n",
    "    logits: Logits tensor, float - [batch_size, NUM_CLASSES].\n",
    "    labels: Labels tensor, int32 - [batch_size], with values in the\n",
    "      range [0, NUM_CLASSES).\n",
    "  Returns:\n",
    "    A scalar int32 tensor with the number of examples (out of batch_size)\n",
    "    that were predicted correctly.\n",
    "  \"\"\"\n",
    "  with tf.variable_scope('val_accuracy') as scope:\n",
    "      correct = tf.equal(tf.argmax(logits,1), tf.argmax(labels,1))\n",
    "      correct = tf.cast(correct, tf.float32)\n",
    "      accuracy = tf.reduce_mean(correct)\n",
    "      print(correct.shape)\n",
    "      tf.summary.scalar(scope.name+'/val_accuracy', accuracy)\n",
    "      return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def trainer(logits, total_batch, batch_size):\n",
    "    sess=tf.Session()\n",
    "    cross_entropy=tf.nn.softmax_cross_entropy_with_logits(labels=labels_ph,logits=logits)\n",
    "    cost=tf.reduce_mean(cross_entropy)\n",
    "    val_cost=tf.reduce_mean(cross_entropy)\n",
    "    tf.summary.scalar(\"cost\",cost)\n",
    "    tf.summary.scalar(\"val_cost\",val_cost)\n",
    "    optimizer=tf.train.AdamOptimizer(learning_rate=LR).minimize(cost)\n",
    "    trainaccuracy = trainacc(logits,labels_ph)\n",
    "    valaccuracy = valacc(logits, labels_ph)\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    writer=tf.summary.FileWriter(model_save_name,graph=tf.get_default_graph())\n",
    "    merged=tf.summary.merge_all()\n",
    "    saver=tf.train.Saver(max_to_keep=4)\n",
    "    counter=0\n",
    "    for epoch in range(epochs):\n",
    "        for batch in range(int(total_batch / batch_size)-1):\n",
    "            counter+=1\n",
    "            batch_images, batch_labels= batch_dispatch(batch_size, batch, images, labels)\n",
    "            \n",
    "\n",
    "            loss, summary=sess.run([cost, merged], feed_dict={images_ph: batch_images, labels_ph: batch_labels})\n",
    "            train_acc=sess.run([trainaccuracy], feed_dict={images_ph: batch_images, labels_ph: batch_labels})\n",
    "\n",
    "            #print('loss',loss)\n",
    "            sess.run(optimizer, feed_dict={images_ph: batch_images, labels_ph: batch_labels})\n",
    "            if batch % 10 == 0:\n",
    "                print('epoch no',epoch, 'batch no',batch,'loss',loss,'train_acc',train_acc)\n",
    "            writer.add_summary(summary,counter)\n",
    "        val_loss,summary=sess.run([val_cost,merged],feed_dict={images_ph: val_images, labels_ph: val_labels})\n",
    "        val_acc=sess.run([valaccuracy],feed_dict={images_ph: val_images, labels_ph: val_labels})\n",
    "        writer.add_summary(summary,counter)\n",
    "\n",
    "        print('epoch_no','epoch','val_loss',val_loss,'val_acc',val_acc)\n",
    "        saver.save(sess, model_save_name)\n",
    "        print('Saved trained model at %s ' % model_save_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 2)\n",
      "WARNING:tensorflow:From <ipython-input-11-9bd28cdb0513>:3: softmax_cross_entropy_with_logits (from tensorflow.python.ops.nn_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "\n",
      "Future major versions of TensorFlow will allow gradients to flow\n",
      "into the labels input on backprop by default.\n",
      "\n",
      "See tf.nn.softmax_cross_entropy_with_logits_v2.\n",
      "\n",
      "(?,)\n",
      "(?,)\n",
      "epoch no 0 batch no 0 loss 13.848972 train_acc [0.40625]\n",
      "epoch no 0 batch no 10 loss 2.7531643 train_acc [0.5]\n",
      "epoch no 0 batch no 20 loss 0.7676078 train_acc [0.5625]\n",
      "epoch no 0 batch no 30 loss 0.70857286 train_acc [0.40625]\n",
      "epoch no 0 batch no 40 loss 0.8039432 train_acc [0.40625]\n",
      "epoch no 0 batch no 50 loss 0.6513021 train_acc [0.59375]\n",
      "epoch no 0 batch no 60 loss 0.7291782 train_acc [0.5625]\n",
      "epoch_no epoch val_loss 0.6850221 val_acc [0.574]\n",
      "Saved trained model at /home/rahulchakwate/My_tensorflow/saved_models/checkpoints\\ \n",
      "epoch no 1 batch no 0 loss 0.6581572 train_acc [0.65625]\n",
      "epoch no 1 batch no 10 loss 0.6625564 train_acc [0.5]\n",
      "epoch no 1 batch no 20 loss 0.6565533 train_acc [0.53125]\n",
      "epoch no 1 batch no 30 loss 0.5957391 train_acc [0.59375]\n",
      "epoch no 1 batch no 40 loss 0.8582226 train_acc [0.5625]\n",
      "epoch no 1 batch no 50 loss 0.6221818 train_acc [0.65625]\n",
      "epoch no 1 batch no 60 loss 0.59430254 train_acc [0.65625]\n",
      "epoch_no epoch val_loss 0.6881118 val_acc [0.578]\n",
      "Saved trained model at /home/rahulchakwate/My_tensorflow/saved_models/checkpoints\\ \n",
      "epoch no 2 batch no 0 loss 0.5878185 train_acc [0.65625]\n",
      "epoch no 2 batch no 10 loss 0.6131444 train_acc [0.625]\n",
      "epoch no 2 batch no 20 loss 0.5414852 train_acc [0.6875]\n",
      "epoch no 2 batch no 30 loss 0.41288963 train_acc [0.8125]\n",
      "epoch no 2 batch no 40 loss 0.5688509 train_acc [0.71875]\n",
      "epoch no 2 batch no 50 loss 0.5034984 train_acc [0.78125]\n",
      "epoch no 2 batch no 60 loss 0.4374473 train_acc [0.71875]\n",
      "epoch_no epoch val_loss 0.7366436 val_acc [0.604]\n",
      "Saved trained model at /home/rahulchakwate/My_tensorflow/saved_models/checkpoints\\ \n",
      "epoch no 3 batch no 0 loss 0.42949674 train_acc [0.71875]\n",
      "epoch no 3 batch no 10 loss 0.4036608 train_acc [0.75]\n",
      "epoch no 3 batch no 20 loss 0.34582588 train_acc [0.875]\n",
      "epoch no 3 batch no 30 loss 0.31053635 train_acc [0.84375]\n",
      "epoch no 3 batch no 40 loss 0.24608317 train_acc [0.96875]\n",
      "epoch no 3 batch no 50 loss 0.27168733 train_acc [0.875]\n",
      "epoch no 3 batch no 60 loss 0.2937134 train_acc [0.90625]\n",
      "epoch_no epoch val_loss 0.900881 val_acc [0.603]\n",
      "Saved trained model at /home/rahulchakwate/My_tensorflow/saved_models/checkpoints\\ \n"
     ]
    }
   ],
   "source": [
    "logits=cnn_model(images_ph,nb_classes)\n",
    "trainer(logits,total_batch, batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
